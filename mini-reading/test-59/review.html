<header>
    <meta charset="UTF-8">
    <meta name="viewport" content="initial-scale=1.0, maximum-scale=1.0, width=device-width, user-scalable=no" />
    <link href="../styles.css" rel="stylesheet" />
</header>
<div>

    <div class="text-center">
        <h2>ROBOTS</h2>
        <img src="robots.jpg" class="img-responsive" style="max-width: 400px; margin: auto;">
    </div>
    <p style="text-align: center;"><strong><em>Since the dawn of human ingenuity, people have devised ever more cunning tools to cope with work that is&nbsp;dangerous, boring, onerous, or just&nbsp;plain nasty. That compulsion has culminated in robotics - the science of conferring various human capabilities on machines.</em></strong></p>
    <p><span style="font-weight: 400;"><strong>A</strong> The modern world is increasingly populated&nbsp;</span>by quasi-intelligent gizmos <span class="explainq1 explain">whose presence we barely notice but whose creeping ubiquity has removed much human drudgery</span>. Our factories hum to the rhythm of robot assembly arms. Our banking is done at automated teller terminals that thank us with rote politeness for the transaction. Our subway trains are controlled by tireless robo- drivers. Our mine shafts are dug by automated moles, and our nuclear accidents - such as those at Three Mile Island and Chernobyl - are cleaned up by robotic muckers fit to withstand radiation.</p>
    <p><span style="font-weight: 400;"><span class="explainq7 explain">Such is the scope of uses envisioned by Karel Capek, the Czech playwright who coined the term ‘robot’ in 1920</span> (the word ‘robota’ means ‘forced labor’ in Czech). As progress accelerates, the experimental becomes the exploitable at record pace.</span></p>
    <p><span style="font-weight: 400;"><strong>B</strong> Other innovations promise to extend the abilities of human operators. Thanks to the incessant miniaturisation of electronics and micro­mechanics, <span class="explainq2 explain">&nbsp;<span class="explainq9 explain"> there are already robot systems that can perform some kinds of brain and bone surgery with submillimeter accuracy</span> - far greater precision than highly skilled physicians can achieve with their hands alone</span>. At the same time, techniques of long-distance control will keep people even farther from hazard. In 1994 a ten- foot-tall NASA robotic explorer called Dante, with video-camera eyes and with spiderlike legs, scrambled over the menacing rim of an Alaskan volcano while technicians 2,000 miles away in California watched the scene by satellite and controlled Dante’s descent.</span></p>
    <p><span style="font-weight: 400;"><strong>C</strong> <span class="explainq3 explain">But if robots are to reach the next stage of labour-saving utility, they will have to operate with less human supervision and be able to make at least a few decisions for themselves - goals that pose a formidable challenge</span>. ‘While we know how to tell a robot to handle a specific error,’ says one expert, ‘we can’t yet give a robot enough common sense to reliably interact with a dynamic world.’ Indeed the quest for true artificial intelligence (Al) has produced very mixed results. Despite a spasm of initial optimism in the 1960s and 1970s, <span class="explainq10 explain">when it appeared that transistor circuits and microprocessors might be able to perform in the same way as the human brain by the 21st century, researchers lately have extended their forecasts by decades if not centuries</span>.</span></p>
    <p><strong>D </strong><span style="font-weight: 400;">What they found, in attempting to model thought, is that the human brain’s roughly one hundred billion neurons are much more talented - and human perception far more complicated - than previously imagined. They have built robots that can recognise the misalignment of a machine panel by a fraction of a millimeter in a controlled factory environment. But the human mind can glimpse a rapidly changing scene and immediately disregard the 98 per cent that is irrelevant, instantaneously focusing on the woodchuck at the side of a winding forest road or the single suspicious face in a tumultuous crowd. <span class="explainq4 explain">The most advanced computer systems on Earth can’t approach that kind of ability</span>, and neuroscientists still don’t know quite how we do it.</span></p>
    <p><strong>E </strong><span style="font-weight: 400;">Nonetheless, as information theorists, neuroscientists, and computer experts pool their talents, <span class="explainq5 explain">they are finding ways to get some lifelike intelligence from robots. One method renounces the linear, logical structure of conventional electronic circuits in favour of the messy, ad hoc arrangement of a real brain’s neurons</span>. These ‘neural networks’ do not have to be programmed. They can ‘teach’ themselves by a system of feedback signals that reinforce electrical pathways that produced correct responses and, conversely, wipe out connections that produced errors. Eventually the net wires itself into a system that can pronounce certain words or distinguish certain shapes.</span></p>
    <p><strong>F </strong><span style="font-weight: 400;"><span class="explainq6 explain">In other areas researchers are struggling to fashion a more natural relationship between people and robots in the expectation that some day machines will take on some tasks now done by humans in, say, nursing homes</span>. This is particularly important in Japan, where the percentage of elderly citizens is rapidly increasing. So experiments at the Science University of Tokyo have created a ‘face robot’ - a life-size, soft plastic model of a female head with <span class="explainq12 explain">a video camera imbedded in the left eye</span> - as a prototype. The researchers’ goal is to create robots that people feel comfortable around. They are concentrating on the face because they believe facial expressions are the most important way to transfer emotional messages. We read those messages by interpreting expressions to decide whether a person is happy, frightened, angry, or nervous. Thus the Japanese robot is designed to detect emotions in the person it is ‘looking at’ by sensing changes in the spatial arrangement of the person’s eyes, nose, eyebrows, and mouth. <span class="explainq13 explain">It compares those configurations with a database of standard facial expressions and guesses the emotion</span>. The robot <span class="explainq14 explain">then uses an ensemble of tiny pressure pads to adjust its plastic face</span> into an appropriate emotional response.</span></p>
    <p><em><span style="font-weight: 400;"><strong>G</strong> </span></em><span style="font-weight: 400;">Other labs are taking a different approach, one that doesn’t try to mimic human intelligence or emotions. Just as computer design has moved away from one central mainframe in favour of myriad individual workstations - and single processors have been replaced by arrays of smaller units that break a big problem into parts that are solved simultaneously - many experts are now investigating whether swarms of semi-smart robots can generate a collective intelligence that is greater than the sum of its parts. That’s what beehives and ant colonies do, and several teams are betting that legions of mini-critters working together like an ant colony could be sent to explore the climate of planets or to inspect pipes in dangerous industrial situations.</span></p>
</div>